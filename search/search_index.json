{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Opteryx","title":"Opteryx"},{"location":"#opteryx","text":"","title":"Opteryx"},{"location":"01%20Getting%20Started/01%20Installation/","text":"Installation opteryx Install via pip (recommended) pip install opteryx opteryx-worker The Opteryx Worker is an optional part of the Query Engine.","title":"Installation"},{"location":"01%20Getting%20Started/01%20Installation/#installation","text":"","title":"Installation"},{"location":"01%20Getting%20Started/01%20Installation/#opteryx","text":"Install via pip (recommended) pip install opteryx","title":"opteryx"},{"location":"01%20Getting%20Started/01%20Installation/#opteryx-worker","text":"The Opteryx Worker is an optional part of the Query Engine.","title":"opteryx-worker"},{"location":"02%20Python%20API/01%20DBAPI/","text":"Python DBAPI Opteryx implements a partial Python DBAPI (PEP-0249) interface. import opteryx conn = opteryx . connect ( project = '' , auth = '' ) cur = conn . cursor () cur . execute ( 'SELECT * FROM memory.movies' ) rows = cur . fetchall ()","title":"Python DBAPI"},{"location":"02%20Python%20API/01%20DBAPI/#python-dbapi","text":"Opteryx implements a partial Python DBAPI (PEP-0249) interface. import opteryx conn = opteryx . connect ( project = '' , auth = '' ) cur = conn . cursor () cur . execute ( 'SELECT * FROM memory.movies' ) rows = cur . fetchall ()","title":"Python DBAPI"},{"location":"03%20SQL/01%20Introduction/","text":"SQL Introduction Concepts Mabel includes a distributed SQL Query Engine, this functionality treats datasets as relations to provide RDBMS query-like capability to mabel datasets.","title":"SQL Introduction"},{"location":"03%20SQL/01%20Introduction/#sql-introduction","text":"","title":"SQL Introduction"},{"location":"03%20SQL/01%20Introduction/#concepts","text":"Mabel includes a distributed SQL Query Engine, this functionality treats datasets as relations to provide RDBMS query-like capability to mabel datasets.","title":"Concepts"},{"location":"03%20SQL/02%20Statements/","text":"SQL Statements SELECT [DISTINCT] FROM WHERE GROUP BY HAVING [LIMIT|SAMPLE] SKIP ORDER BY [ASC|DESC] -> row data ANALYZE TABLE table_name -> Name: DataSet Name Format: File Type Rows: Row Count <- from the BRIN Blobs: Blob Count Bytes: Raw Byte Count Columns: List of columns and types EXPLAIN query -> returns the plan for a query CREATE INDEX index_name ON dataset . name ( columns )","title":"SQL Statements"},{"location":"03%20SQL/02%20Statements/#sql-statements","text":"SELECT [DISTINCT] FROM WHERE GROUP BY HAVING [LIMIT|SAMPLE] SKIP ORDER BY [ASC|DESC] -> row data ANALYZE TABLE table_name -> Name: DataSet Name Format: File Type Rows: Row Count <- from the BRIN Blobs: Blob Count Bytes: Raw Byte Count Columns: List of columns and types EXPLAIN query -> returns the plan for a query CREATE INDEX index_name ON dataset . name ( columns )","title":"SQL Statements"},{"location":"03%20SQL/03%20Syntax/","text":"SQL Syntax FROM WHERE $DATE is a special term, allowing you to specify partitions in SQL, can be used in WHERE clauses like any other field. If used, it will replace any dates provided as parameters. WHERE $DATE BETWEEN <start_date> AND <end_date> WHERE $DATE > '2021-01-02' WHERE $DATE = TODAY() GROUP BY HAVING ORDER BY LIMIT CREATE WITH","title":"SQL Syntax"},{"location":"03%20SQL/03%20Syntax/#sql-syntax","text":"","title":"SQL Syntax"},{"location":"03%20SQL/03%20Syntax/#from","text":"","title":"FROM"},{"location":"03%20SQL/03%20Syntax/#where","text":"$DATE is a special term, allowing you to specify partitions in SQL, can be used in WHERE clauses like any other field. If used, it will replace any dates provided as parameters. WHERE $DATE BETWEEN <start_date> AND <end_date> WHERE $DATE > '2021-01-02' WHERE $DATE = TODAY()","title":"WHERE"},{"location":"03%20SQL/03%20Syntax/#group-by","text":"","title":"GROUP BY"},{"location":"03%20SQL/03%20Syntax/#having","text":"","title":"HAVING"},{"location":"03%20SQL/03%20Syntax/#order-by","text":"","title":"ORDER BY"},{"location":"03%20SQL/03%20Syntax/#limit","text":"","title":"LIMIT"},{"location":"03%20SQL/03%20Syntax/#create","text":"","title":"CREATE"},{"location":"03%20SQL/03%20Syntax/#with","text":"","title":"WITH"},{"location":"03%20SQL/04%20Data%20Types/","text":"SQL Data Types Types Name Description BOOLEAN Logical boolean (True/False). NUMERIC All numeric types LIST An ordered sequence of data values. VARCHAR Variable-length character string. STRUCT A dictionary of multiple named values, where each key is a string, but the value can be a different type for each key. TIMESTAMP Combination of date and time. OTHER None of the above or multiple types in the same column. BOOLEAN Columns of type BOOLEAN cannot be indexed. NUMERIC Type Hint in Queries NUMERIC('value') LIST Columns of type LIST cannot be indexed. Formatted as (value1, value2, ...) VARCHAR STRUCT Columns of type STRUCT cannot be indexed. TIMESTAMP Mabel will implicitly interpret strings formatted as 'YYYY-MM-DD' or 'YYYY-MM-DD HH:MM' as TIMESTAMP Type Hint in Queries TIMESTAMP('value') OTHER DataSets with columns of type OTHER cannot have DISTINCT functions applied. Columns of type OTHER cannot be indexed.","title":"SQL Data Types"},{"location":"03%20SQL/04%20Data%20Types/#sql-data-types","text":"","title":"SQL Data Types"},{"location":"03%20SQL/04%20Data%20Types/#types","text":"Name Description BOOLEAN Logical boolean (True/False). NUMERIC All numeric types LIST An ordered sequence of data values. VARCHAR Variable-length character string. STRUCT A dictionary of multiple named values, where each key is a string, but the value can be a different type for each key. TIMESTAMP Combination of date and time. OTHER None of the above or multiple types in the same column.","title":"Types"},{"location":"03%20SQL/04%20Data%20Types/#boolean","text":"Columns of type BOOLEAN cannot be indexed.","title":"BOOLEAN"},{"location":"03%20SQL/04%20Data%20Types/#numeric","text":"Type Hint in Queries NUMERIC('value')","title":"NUMERIC"},{"location":"03%20SQL/04%20Data%20Types/#list","text":"Columns of type LIST cannot be indexed. Formatted as (value1, value2, ...)","title":"LIST"},{"location":"03%20SQL/04%20Data%20Types/#varchar","text":"","title":"VARCHAR"},{"location":"03%20SQL/04%20Data%20Types/#struct","text":"Columns of type STRUCT cannot be indexed.","title":"STRUCT"},{"location":"03%20SQL/04%20Data%20Types/#timestamp","text":"Mabel will implicitly interpret strings formatted as 'YYYY-MM-DD' or 'YYYY-MM-DD HH:MM' as TIMESTAMP Type Hint in Queries TIMESTAMP('value')","title":"TIMESTAMP"},{"location":"03%20SQL/04%20Data%20Types/#other","text":"DataSets with columns of type OTHER cannot have DISTINCT functions applied. Columns of type OTHER cannot be indexed.","title":"OTHER"},{"location":"03%20SQL/05%20Expressions/","text":"SQL Expressions Logical NOT <- to be implemented The following logical operators are available: AND and OR . a b a AND b a OR b TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE The operators AND and OR are commutative, that is, you can switch the left and right operand without affecting the result. Comparison Operators Operator Description Example Result < less than 2 < 3 TRUE > greater than 2 > 3 FALSE <= less than or equal to 2 <= 3 TRUE >= greater than or equal to 4 >= 8 TRUE = equal to 3 = 4 FALSE <> not equal to 2 <> 2 FALSE IN value in list NOT IN value not in list LIKE pattern match NOT LIKE inverse of LIKE ILIKE case-insensitive pattern match NOT ILIKE inverse of ILIKE ~ regular expression match Other Comparisons Predicate Description a BETWEEN x AND y equivalent to a >= x AND a <= y a NOT BETWEEN x AND y equivalent to a < x OR a > y Casting CAST( AS ) DECIMAL() Subqueries NOT IMPLEMENTED","title":"SQL Expressions"},{"location":"03%20SQL/05%20Expressions/#sql-expressions","text":"","title":"SQL Expressions"},{"location":"03%20SQL/05%20Expressions/#logical","text":"NOT <- to be implemented The following logical operators are available: AND and OR . a b a AND b a OR b TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE The operators AND and OR are commutative, that is, you can switch the left and right operand without affecting the result.","title":"Logical"},{"location":"03%20SQL/05%20Expressions/#comparison-operators","text":"Operator Description Example Result < less than 2 < 3 TRUE > greater than 2 > 3 FALSE <= less than or equal to 2 <= 3 TRUE >= greater than or equal to 4 >= 8 TRUE = equal to 3 = 4 FALSE <> not equal to 2 <> 2 FALSE IN value in list NOT IN value not in list LIKE pattern match NOT LIKE inverse of LIKE ILIKE case-insensitive pattern match NOT ILIKE inverse of ILIKE ~ regular expression match","title":"Comparison Operators"},{"location":"03%20SQL/05%20Expressions/#other-comparisons","text":"Predicate Description a BETWEEN x AND y equivalent to a >= x AND a <= y a NOT BETWEEN x AND y equivalent to a < x OR a > y","title":"Other Comparisons"},{"location":"03%20SQL/05%20Expressions/#casting","text":"CAST( AS ) DECIMAL()","title":"Casting"},{"location":"03%20SQL/05%20Expressions/#subqueries","text":"NOT IMPLEMENTED","title":"Subqueries"},{"location":"03%20SQL/06%20Functions/","text":"SQL Functions Numeric Functions Text Functions Date Functions","title":"SQL Functions"},{"location":"03%20SQL/06%20Functions/#sql-functions","text":"","title":"SQL Functions"},{"location":"03%20SQL/06%20Functions/#numeric-functions","text":"","title":"Numeric Functions"},{"location":"03%20SQL/06%20Functions/#text-functions","text":"","title":"Text Functions"},{"location":"03%20SQL/06%20Functions/#date-functions","text":"","title":"Date Functions"},{"location":"03%20SQL/07%20Aggregations/","text":"SQL Aggregations SUM MAX MIN COUNT AVG PERCENT // not implemented - new version 0.6 calculate the %age of total items this group represents APPROX_DISTINCT // not implemented - new version 0.6 get an approximate for the distinct values in this group (uses HyperLogLog)","title":"SQL Aggregations"},{"location":"03%20SQL/07%20Aggregations/#sql-aggregations","text":"","title":"SQL Aggregations"},{"location":"03%20SQL/07%20Aggregations/#sum","text":"","title":"SUM"},{"location":"03%20SQL/07%20Aggregations/#max","text":"","title":"MAX"},{"location":"03%20SQL/07%20Aggregations/#min","text":"","title":"MIN"},{"location":"03%20SQL/07%20Aggregations/#count","text":"","title":"COUNT"},{"location":"03%20SQL/07%20Aggregations/#avg","text":"","title":"AVG"},{"location":"03%20SQL/07%20Aggregations/#percent-not-implemented-new-version-06","text":"calculate the %age of total items this group represents","title":"PERCENT // not implemented - new version 0.6"},{"location":"03%20SQL/07%20Aggregations/#approx_distinct-not-implemented-new-version-06","text":"get an approximate for the distinct values in this group (uses HyperLogLog)","title":"APPROX_DISTINCT // not implemented - new version 0.6"},{"location":"03%20SQL/08%20Examples/","text":"SQL Examples","title":"SQL Examples"},{"location":"03%20SQL/08%20Examples/#sql-examples","text":"","title":"SQL Examples"},{"location":"03%20SQL/09%20Advanced/","text":"Advanced SQL","title":"Advanced SQL"},{"location":"03%20SQL/09%20Advanced/#advanced-sql","text":"","title":"Advanced SQL"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/","text":"Storage Formats Data Files JSONL Raw and zStandard compressed. Files don't need an explicit schema, but each partition must have the same columns in the same order in every row of every file. Parquet Parquet offers optimizations not available with other formats which are likely to improve query performance. If a datasource has query performance issues or is hot in terms of query use, converting to Parquet is likely to improve performance. Do not take this as true for all situations, do test for your specific circumstances. ORC Other Files ZoneMap Indexes *. .index e.g. datafile.btree.index Frame Markers frame.complete frame.invalid","title":"Storage Formats"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/#storage-formats","text":"","title":"Storage Formats"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/#data-files","text":"JSONL Raw and zStandard compressed. Files don't need an explicit schema, but each partition must have the same columns in the same order in every row of every file. Parquet Parquet offers optimizations not available with other formats which are likely to improve query performance. If a datasource has query performance issues or is hot in terms of query use, converting to Parquet is likely to improve performance. Do not take this as true for all situations, do test for your specific circumstances. ORC","title":"Data Files"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/#other-files","text":"","title":"Other Files"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/#zonemap","text":"","title":"ZoneMap"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/#indexes","text":"*. .index e.g. datafile.btree.index","title":"Indexes"},{"location":"04%20Internals/01%20Storage%20Engine/01%20Storage%20Formats/#frame-markers","text":"frame.complete frame.invalid","title":"Frame Markers"},{"location":"04%20Internals/01%20Storage%20Engine/02%20Storage%20Layout/","text":"Storage Layout Opinionated Mabel datasets. The 'raw' data is JSONL in 64Mb chunks with ZSTD compression. The database-engine MUST be able to support this format (and other 'raw' formats) to be broadly useful. A side-car file for each dataset (the folder of partitions) provides information to optimize database performance, a .map file. This is a JSON file which contains schema and zonemap information. .index files also exist as sidecar files: [].bitmap.index [].btree.index The schema is used to speed up reading into a Relation (as opposed to reading into a DictSet). Relations are smaller and faster than DictSets and are the internal representation for the query-engine.","title":"Storage Layout"},{"location":"04%20Internals/01%20Storage%20Engine/02%20Storage%20Layout/#storage-layout","text":"Opinionated Mabel datasets. The 'raw' data is JSONL in 64Mb chunks with ZSTD compression. The database-engine MUST be able to support this format (and other 'raw' formats) to be broadly useful. A side-car file for each dataset (the folder of partitions) provides information to optimize database performance, a .map file. This is a JSON file which contains schema and zonemap information. .index files also exist as sidecar files: [].bitmap.index [].btree.index The schema is used to speed up reading into a Relation (as opposed to reading into a DictSet). Relations are smaller and faster than DictSets and are the internal representation for the query-engine.","title":"Storage Layout"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/","text":"Storage Adapters Local Disk Network Google Cloud Storage AWS S3 (Minio)","title":"Storage Adapters"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/#storage-adapters","text":"","title":"Storage Adapters"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/#local","text":"","title":"Local"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/#disk","text":"","title":"Disk"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/#network","text":"","title":"Network"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/#google-cloud-storage","text":"","title":"Google Cloud Storage"},{"location":"04%20Internals/01%20Storage%20Engine/03%20Storage%20Adapters/#aws-s3-minio","text":"","title":"AWS S3 (Minio)"},{"location":"04%20Internals/01%20Storage%20Engine/04%20Reading%20Data/","text":"The reader will perform a scan of directory prefixes to determine which partitions need to be read. Each partition is self-contained and contains all of the information to process it, the reader will distribute the work to read partitions, there are three options: 1) Inline - this is the simplest but the slowest, all reads are performed sequentionally in the one process. 2) Multi-process - this is usually faster than Inline, reads are distributed between multiple processes running on the same computer. 3) Distributed - this isn't written yet. The reader will collect a list of the files in the partition, these will be: data files metedata files (frame.metadata) index files (*.index) directives (frame.invalid / frame.complete) The reader has the following steps: [partition name, columns to return, columns being filtered on, the filter (dnf)] determine which frame to read (the latest complete, but not invalidated frame) determine the scheme of the data from the zonemap, if there isn't one we'll fake one later determine which blobs in the partition to read (using the zonemap, or read them all) for each blob to be read: if there's any indexes which can be used work out which rows to process determine which 'driver' to use to read the blob read the blob into records, selecting only the records identified after applying the indexes and projecting only the columns passed to the reader","title":"04 Reading Data"},{"location":"04%20Internals/02%20Query%20Engine/01%20Parser/","text":"Parser MySQL flavoured parser sqloxide Python bindings for sqlparser-rs","title":"Parser"},{"location":"04%20Internals/02%20Query%20Engine/01%20Parser/#parser","text":"MySQL flavoured parser sqloxide Python bindings for sqlparser-rs","title":"Parser"},{"location":"04%20Internals/02%20Query%20Engine/02%20Planner/","text":"Query Planner Query Plan PartitionReaderNode (read a partition, includes selection and projection pushdowns) ProjectNode (remove unwanted columns including renames) SelectionNode (find records matching a predicate) JoinNode (currently only INNER JOIN) SortNode (order a relation by given keys) GroupNode (put a relation into groups - GROUP BY) AggregateNode (group by MIN/MAX/AVG etc CombineNode (combine sketches and aggregations) Limit - Top N records Distinct Merge - append sets to each other Evaluate () Index (create an index, can be temporary or persisted) Query Plan Optimizer // query optimizer Define static rules that transform logical operators to a physical plan. \u2192 Perform most restrictive selection early \u2192 Perform all selections before joins \u2192 Predicate/Limit/Projection pushdowns \u2192 Join ordering based on cardinality -> if it's count(*) if we can get the result from the zonemap - do that otherwise - reduce the record to a hash only as early as possible -> if we have a group by with a lot of duplication (cardinality estimates), use the index tree to build the groups.","title":"Query Planner"},{"location":"04%20Internals/02%20Query%20Engine/02%20Planner/#query-planner","text":"","title":"Query Planner"},{"location":"04%20Internals/02%20Query%20Engine/02%20Planner/#query-plan","text":"PartitionReaderNode (read a partition, includes selection and projection pushdowns) ProjectNode (remove unwanted columns including renames) SelectionNode (find records matching a predicate) JoinNode (currently only INNER JOIN) SortNode (order a relation by given keys) GroupNode (put a relation into groups - GROUP BY) AggregateNode (group by MIN/MAX/AVG etc CombineNode (combine sketches and aggregations) Limit - Top N records Distinct Merge - append sets to each other Evaluate () Index (create an index, can be temporary or persisted)","title":"Query Plan"},{"location":"04%20Internals/02%20Query%20Engine/02%20Planner/#query-plan-optimizer","text":"// query optimizer Define static rules that transform logical operators to a physical plan. \u2192 Perform most restrictive selection early \u2192 Perform all selections before joins \u2192 Predicate/Limit/Projection pushdowns \u2192 Join ordering based on cardinality -> if it's count(*) if we can get the result from the zonemap - do that otherwise - reduce the record to a hash only as early as possible -> if we have a group by with a lot of duplication (cardinality estimates), use the index tree to build the groups.","title":"Query Plan Optimizer"},{"location":"04%20Internals/02%20Query%20Engine/03%20Execution/","text":"Query Execution Overview The planner creates a plan as a DAG or Tree, below is a simplified query plan: graph LR A[LIMIT 10] --> B[SELECT *] B --> C[WHERE Alive = TRUE] C --> D[FROM data_table] Note that the query plan order does not match the order that the query is written, instead it runs in the order required to respond to the query. The execution engine starts at the node at left of the tree (LIMIT 10) and requests records from the node below (SELECT *), which in turn requests records from the node to the right (WHERE Alive = TRUE). This continues until we reach a node which can feed data into the tree, this will usually be at a node which reads data files (FROM data_table). Records are read in batches, and processed in batches, so although the leftmost node will emit it's result when it has 10 records, it may have recieved 1000 records. These batches are the data frames with broadly align to the database concept of data pages.","title":"Query Execution"},{"location":"04%20Internals/02%20Query%20Engine/03%20Execution/#query-execution","text":"","title":"Query Execution"},{"location":"04%20Internals/02%20Query%20Engine/03%20Execution/#overview","text":"The planner creates a plan as a DAG or Tree, below is a simplified query plan: graph LR A[LIMIT 10] --> B[SELECT *] B --> C[WHERE Alive = TRUE] C --> D[FROM data_table] Note that the query plan order does not match the order that the query is written, instead it runs in the order required to respond to the query. The execution engine starts at the node at left of the tree (LIMIT 10) and requests records from the node below (SELECT *), which in turn requests records from the node to the right (WHERE Alive = TRUE). This continues until we reach a node which can feed data into the tree, this will usually be at a node which reads data files (FROM data_table). Records are read in batches, and processed in batches, so although the leftmost node will emit it's result when it has 10 records, it may have recieved 1000 records. These batches are the data frames with broadly align to the database concept of data pages.","title":"Overview"},{"location":"04%20Internals/03%20Data%20Structures/01%20Relation/","text":"Relation A relation is a representation of a data set (complete or partial).","title":"Relation"},{"location":"04%20Internals/03%20Data%20Structures/01%20Relation/#relation","text":"A relation is a representation of a data set (complete or partial).","title":"Relation"},{"location":"04%20Internals/04%20Algorithms/01%20Indexes/","text":"Types Type Description Binary Tree MinMax Cardinality Index strategy sets with less than 1000 rows are not indexed, the cost of using an index is likely to exceed the benefits. columns being used for SARGABLE comparisons later in the DAG have a tree created for them. Indexes can be single columns only.","title":"01 Indexes"},{"location":"04%20Internals/04%20Algorithms/01%20Indexes/#types","text":"Type Description Binary Tree MinMax Cardinality","title":"Types"},{"location":"04%20Internals/04%20Algorithms/01%20Indexes/#index-strategy","text":"sets with less than 1000 rows are not indexed, the cost of using an index is likely to exceed the benefits. columns being used for SARGABLE comparisons later in the DAG have a tree created for them. Indexes can be single columns only.","title":"Index strategy"},{"location":"04%20Internals/04%20Algorithms/02%20Data%20Sketches/","text":"Data Sketches Key uses in two place: - query planning (e.g. to estimate cardinality) - APPROX aggregations DISTINCT COUNTING BloomFilter HyperLogLog MOST FREQUENT LossyCounter QUANTILES & HISTOGRAMS T-Digest","title":"Data Sketches"},{"location":"04%20Internals/04%20Algorithms/02%20Data%20Sketches/#data-sketches","text":"Key uses in two place: - query planning (e.g. to estimate cardinality) - APPROX aggregations","title":"Data Sketches"},{"location":"04%20Internals/04%20Algorithms/02%20Data%20Sketches/#distinct-counting","text":"BloomFilter HyperLogLog","title":"DISTINCT COUNTING"},{"location":"04%20Internals/04%20Algorithms/02%20Data%20Sketches/#most-frequent","text":"LossyCounter","title":"MOST FREQUENT"},{"location":"04%20Internals/04%20Algorithms/02%20Data%20Sketches/#quantiles-histograms","text":"T-Digest","title":"QUANTILES &amp; HISTOGRAMS"},{"location":"04%20Internals/04%20Algorithms/03%20Joins/","text":"Joins if one dataset is small - we keep that in memory and pass over the second dataset if both are large, a Binary Tree is created for the set with the smallest number of unique values, we then go over the larger set, looking up the join in the index, no match - discard, match - get the value from the smaller set.","title":"Joins"},{"location":"04%20Internals/04%20Algorithms/03%20Joins/#joins","text":"if one dataset is small - we keep that in memory and pass over the second dataset if both are large, a Binary Tree is created for the set with the smallest number of unique values, we then go over the larger set, looking up the join in the index, no match - discard, match - get the value from the smaller set.","title":"Joins"},{"location":"05%20Optimization/01%20Caching.md/","text":"Caching Buffer Pool Read cache, saving a copy of data stored remotely to a faster store. Results Cache caching of query results so identical queries use the result of a previous execution.","title":"Caching"},{"location":"05%20Optimization/01%20Caching.md/#caching","text":"","title":"Caching"},{"location":"05%20Optimization/01%20Caching.md/#buffer-pool","text":"Read cache, saving a copy of data stored remotely to a faster store.","title":"Buffer Pool"},{"location":"05%20Optimization/01%20Caching.md/#results-cache","text":"caching of query results so identical queries use the result of a previous execution.","title":"Results Cache"},{"location":"05%20Optimization/02%20Storage/","text":"Storage Optimization Use Parquet to store data, parquet is fast to process and offers optimizations not available for other formats. sort data by the most frequent filters and use zonemaps - zone maps allow for pruning of blobs, its faster to prune data than to filter it away.","title":"Storage Optimization"},{"location":"05%20Optimization/02%20Storage/#storage-optimization","text":"Use Parquet to store data, parquet is fast to process and offers optimizations not available for other formats. sort data by the most frequent filters and use zonemaps - zone maps allow for pruning of blobs, its faster to prune data than to filter it away.","title":"Storage Optimization"},{"location":"05%20Optimization/03%20Query%20Optimization/","text":"Query Optimization 1. Avoid SELECT * Selecting only the fields you need to be returned improves query performance by reducing the amount of data that is processed internally. A principle the Query Optimizer uses is to eliminate rows and columns to process as early as possible, SELECT * removes the option to remove columns from the data being processed. 2. Prune Early Using date selectors (or the $PARTITION filters) to limit the date range over will limit the number of partitions that need need to be read. Not reading the record is faster than reading and working out if it needs to be filtered out of the result set.","title":"Query Optimization"},{"location":"05%20Optimization/03%20Query%20Optimization/#query-optimization","text":"","title":"Query Optimization"},{"location":"05%20Optimization/03%20Query%20Optimization/#1-avoid-select","text":"Selecting only the fields you need to be returned improves query performance by reducing the amount of data that is processed internally. A principle the Query Optimizer uses is to eliminate rows and columns to process as early as possible, SELECT * removes the option to remove columns from the data being processed.","title":"1. Avoid SELECT *"},{"location":"05%20Optimization/03%20Query%20Optimization/#2-prune-early","text":"Using date selectors (or the $PARTITION filters) to limit the date range over will limit the number of partitions that need need to be read. Not reading the record is faster than reading and working out if it needs to be filtered out of the result set.","title":"2. Prune Early"},{"location":"06%20Roadmap/Queries/","text":"if a Index can be used to respond to a query - e.g. only one column is needed from a table, and it has a binary tree index, just use the index - OR if the query is a COUNT and we have a BRIN, use that.","title":"Queries"},{"location":"07%20Change%20Log/07.01%20version%200.1.0/","text":"Version 0.1.0 Differences from Mabel 0.5 Stricter ANSI SQL compliance double quotes indicate database identifier","title":"Version 0.1.0"},{"location":"07%20Change%20Log/07.01%20version%200.1.0/#version-010","text":"Differences from Mabel 0.5 Stricter ANSI SQL compliance double quotes indicate database identifier","title":"Version 0.1.0"}]}